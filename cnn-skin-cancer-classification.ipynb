{"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPWAdiAnfGe4o14mtBjM3gv","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,Dense,MaxPool2D,Activation,Dropout,Flatten\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import BatchNormalization\nimport os \nimport pandas as pd\nimport plotly.graph_objs as go\nimport matplotlib.ticker as ticker\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D","metadata":{"id":"7E4qgkp_wGaE"},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install opendatasets\nimport opendatasets as od\nod.download('https://www.kaggle.com/datasets/amrragababdelaziz/dermnet-and-skin-disease-9-classes')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90021,"status":"ok","timestamp":1676954763194,"user":{"displayName":"Knight Silver","userId":"13083360196547457823"},"user_tz":-330},"id":"MeTMtosYpVKS","outputId":"a0a8fe97-9e34-4b46-e0ef-1a8fcaf9f2d5"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: opendatasets in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (0.1.22)\n\nRequirement already satisfied: kaggle in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from opendatasets) (1.5.13)\n\nRequirement already satisfied: tqdm in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from opendatasets) (4.65.0)\n\nRequirement already satisfied: click in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from opendatasets) (8.0.4)\n\nRequirement already satisfied: colorama in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from click->opendatasets) (0.4.6)\n\nRequirement already satisfied: requests in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from kaggle->opendatasets) (2.28.1)\n\nRequirement already satisfied: six>=1.10 in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n\nRequirement already satisfied: python-dateutil in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n\nRequirement already satisfied: urllib3 in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from kaggle->opendatasets) (1.26.14)\n\nRequirement already satisfied: certifi in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from kaggle->opendatasets) (2022.12.7)\n\nRequirement already satisfied: python-slugify in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from kaggle->opendatasets) (8.0.1)\n\nRequirement already satisfied: text-unidecode>=1.3 in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n\nRequirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.4)\n\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\rubin\\anaconda3\\envs\\skin_cancer\\lib\\site-packages (from requests->kaggle->opendatasets) (3.4)\n\nPlease provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n\nYour Kaggle username: rubinie\n\nYour Kaggle Key: ········\n\nDownloading dermnet-and-skin-disease-9-classes.zip to .\\dermnet-and-skin-disease-9-classes\n"},{"name":"stderr","output_type":"stream","text":"100%|█████████████████████████████████████████████████████████████████████████████| 3.51G/3.51G [03:48<00:00, 16.5MB/s]\n"},{"name":"stdout","output_type":"stream","text":"\n"}]},{"cell_type":"code","source":"train ='C:\\\\Users\\\\rubin\\\\Videos\\\\FINAL REVIEW\\\\9-Skin-Cancer\\\\Merged Dataset\\\\Train'\nvalidation_dir = 'C:\\\\Users\\\\rubin\\\\Videos\\\\FINAL REVIEW\\\\9-Skin-Cancer\\\\Merged Dataset\\\\test'","metadata":{"id":"0nuwrNtguWJr"},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import glob\ndef get_files(directory):\n  if not os.path.exists(directory):\n    return 0\n  count=0\n  for current_path,dirs,files in os.walk(directory):\n    for dr in dirs:\n      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n  return count","metadata":{"id":"boFpeNSVwTX2"},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_samples =get_files(train)\nnum_classes=len(glob.glob(train+\"/*\"))\ntest_samples=get_files(validation_dir)\nprint(num_classes,\"Classes\")\nprint(train_samples,\"Train images\")\nprint(test_samples,\"Test images\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1676954763195,"user":{"displayName":"Knight Silver","userId":"13083360196547457823"},"user_tz":-330},"id":"5ACoTgXkv4dt","outputId":"6f04f06f-4494-40a2-d194-9a7d68b4b908"},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"9 Classes\n\n26642 Train images\n\n2389 Test images\n"}]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen=ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\ntest_datagen=ImageDataGenerator(rescale=1./255)\nimg_width,img_height =224,224\ninput_shape=(img_width,img_height,3)\nbatch_size =64\ntrain_generator =train_datagen.flow_from_directory(train,\n                                target_size=(img_width,img_height),batch_size=batch_size)\ntest_generator=test_datagen.flow_from_directory(validation_dir,shuffle=True,target_size=(img_width,img_height),batch_size=batch_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1676954763196,"user":{"displayName":"Knight Silver","userId":"13083360196547457823"},"user_tz":-330},"id":"sfiUXK6evyTD","outputId":"e3f1f992-cd77-4262-f460-19e48e659aeb"},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"Found 26642 images belonging to 9 classes.\n\nFound 2389 images belonging to 9 classes.\n"}]},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras import layers\nmodel = keras.Sequential([\n    layers.Input((224, 224, 3)),\n    \n    layers.Conv2D(16, 3, activation=\"relu\"),\n    layers.BatchNormalization(), # Regularization\n    layers.MaxPooling2D(), \n    \n    layers.Conv2D(32, 3, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n    \n    layers.Conv2D(64, 3, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(),\n    \n    layers.Flatten(),\n    \n    layers.Dense(64, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2), # Regularization\n    layers.Dense(9, activation=\"softmax\"),\n])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"id":"5X8TQ6X3uBsY"},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\nhistory = model.fit(train_generator,validation_data=test_generator,epochs=70,shuffle=True)","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nQLqCFdEyX4U","outputId":"d8199180-be77-4dfe-bbcb-95e93c84a236"},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/70\n\n417/417 [==============================] - 625s 1s/step - loss: 1.6646 - accuracy: 0.4160 - val_loss: 2.6614 - val_accuracy: 0.1444\n\nEpoch 2/70\n\n417/417 [==============================] - 615s 1s/step - loss: 1.4247 - accuracy: 0.4920 - val_loss: 1.8593 - val_accuracy: 0.3349\n\nEpoch 3/70\n\n417/417 [==============================] - 611s 1s/step - loss: 1.3237 - accuracy: 0.5206 - val_loss: 1.8801 - val_accuracy: 0.3474\n\nEpoch 4/70\n\n417/417 [==============================] - 608s 1s/step - loss: 1.2559 - accuracy: 0.5528 - val_loss: 2.1767 - val_accuracy: 0.2537\n\nEpoch 5/70\n\n417/417 [==============================] - 605s 1s/step - loss: 1.1965 - accuracy: 0.5712 - val_loss: 1.6724 - val_accuracy: 0.4165\n\nEpoch 6/70\n\n417/417 [==============================] - 607s 1s/step - loss: 1.1435 - accuracy: 0.5941 - val_loss: 1.6150 - val_accuracy: 0.4391\n\nEpoch 7/70\n\n417/417 [==============================] - 593s 1s/step - loss: 1.0811 - accuracy: 0.6192 - val_loss: 1.8912 - val_accuracy: 0.3382\n\nEpoch 8/70\n\n417/417 [==============================] - 596s 1s/step - loss: 1.0296 - accuracy: 0.6403 - val_loss: 1.6474 - val_accuracy: 0.4412\n\nEpoch 9/70\n\n417/417 [==============================] - 597s 1s/step - loss: 0.9887 - accuracy: 0.6545 - val_loss: 1.5811 - val_accuracy: 0.4646\n\nEpoch 10/70\n\n417/417 [==============================] - 603s 1s/step - loss: 0.9468 - accuracy: 0.6724 - val_loss: 1.5407 - val_accuracy: 0.4906\n\nEpoch 11/70\n\n417/417 [==============================] - 592s 1s/step - loss: 0.9022 - accuracy: 0.6839 - val_loss: 1.5142 - val_accuracy: 0.4885\n\nEpoch 12/70\n\n417/417 [==============================] - 622s 1s/step - loss: 0.8664 - accuracy: 0.6996 - val_loss: 1.4174 - val_accuracy: 0.5228\n\nEpoch 13/70\n\n417/417 [==============================] - 631s 2s/step - loss: 0.8257 - accuracy: 0.7128 - val_loss: 1.6703 - val_accuracy: 0.5040\n\nEpoch 14/70\n\n417/417 [==============================] - 614s 1s/step - loss: 0.7903 - accuracy: 0.7281 - val_loss: 1.5889 - val_accuracy: 0.4751\n\nEpoch 15/70\n\n417/417 [==============================] - 616s 1s/step - loss: 0.7532 - accuracy: 0.7421 - val_loss: 1.4835 - val_accuracy: 0.5119\n\nEpoch 16/70\n\n417/417 [==============================] - 621s 1s/step - loss: 0.7365 - accuracy: 0.7457 - val_loss: 1.4294 - val_accuracy: 0.5249\n\nEpoch 17/70\n\n417/417 [==============================] - 616s 1s/step - loss: 0.7152 - accuracy: 0.7539 - val_loss: 1.3359 - val_accuracy: 0.5550\n\nEpoch 18/70\n\n417/417 [==============================] - 607s 1s/step - loss: 0.6873 - accuracy: 0.7646 - val_loss: 1.5032 - val_accuracy: 0.5350\n\nEpoch 19/70\n\n417/417 [==============================] - 636s 2s/step - loss: 0.6627 - accuracy: 0.7726 - val_loss: 1.1593 - val_accuracy: 0.6300\n\nEpoch 20/70\n\n417/417 [==============================] - 612s 1s/step - loss: 0.6480 - accuracy: 0.7782 - val_loss: 1.2444 - val_accuracy: 0.6132\n\nEpoch 21/70\n\n417/417 [==============================] - 620s 1s/step - loss: 0.6185 - accuracy: 0.7895 - val_loss: 1.2290 - val_accuracy: 0.6107\n\nEpoch 22/70\n\n417/417 [==============================] - 608s 1s/step - loss: 0.5949 - accuracy: 0.7945 - val_loss: 1.2209 - val_accuracy: 0.6203\n\nEpoch 23/70\n\n417/417 [==============================] - 619s 1s/step - loss: 0.5976 - accuracy: 0.7952 - val_loss: 1.2273 - val_accuracy: 0.6149\n\nEpoch 24/70\n\n417/417 [==============================] - 614s 1s/step - loss: 0.5707 - accuracy: 0.8035 - val_loss: 1.0380 - val_accuracy: 0.6794\n\nEpoch 25/70\n\n417/417 [==============================] - 617s 1s/step - loss: 0.5513 - accuracy: 0.8115 - val_loss: 1.2143 - val_accuracy: 0.6450\n\nEpoch 26/70\n\n417/417 [==============================] - 610s 1s/step - loss: 0.5380 - accuracy: 0.8172 - val_loss: 1.3061 - val_accuracy: 0.6199\n\nEpoch 27/70\n\n417/417 [==============================] - 615s 1s/step - loss: 0.5315 - accuracy: 0.8200 - val_loss: 1.1141 - val_accuracy: 0.6534\n\nEpoch 28/70\n\n417/417 [==============================] - 613s 1s/step - loss: 0.5184 - accuracy: 0.8244 - val_loss: 1.3262 - val_accuracy: 0.6178\n\nEpoch 29/70\n\n417/417 [==============================] - 624s 1s/step - loss: 0.5055 - accuracy: 0.8291 - val_loss: 0.9545 - val_accuracy: 0.7200\n\nEpoch 30/70\n\n417/417 [==============================] - 623s 1s/step - loss: 0.4972 - accuracy: 0.8272 - val_loss: 1.4195 - val_accuracy: 0.5944\n\nEpoch 31/70\n\n417/417 [==============================] - 622s 1s/step - loss: 0.4668 - accuracy: 0.8386 - val_loss: 0.9680 - val_accuracy: 0.7141\n\nEpoch 32/70\n\n417/417 [==============================] - 610s 1s/step - loss: 0.4727 - accuracy: 0.8380 - val_loss: 1.0945 - val_accuracy: 0.6743\n\nEpoch 33/70\n\n417/417 [==============================] - 617s 1s/step - loss: 0.4553 - accuracy: 0.8430 - val_loss: 1.1664 - val_accuracy: 0.6542\n\nEpoch 34/70\n\n417/417 [==============================] - 621s 1s/step - loss: 0.4590 - accuracy: 0.8454 - val_loss: 1.5581 - val_accuracy: 0.5910\n\nEpoch 35/70\n\n417/417 [==============================] - 623s 1s/step - loss: 0.4380 - accuracy: 0.8481 - val_loss: 1.8559 - val_accuracy: 0.5370\n\nEpoch 36/70\n\n417/417 [==============================] - 630s 2s/step - loss: 0.4410 - accuracy: 0.8504 - val_loss: 0.9485 - val_accuracy: 0.7124\n\nEpoch 37/70\n\n417/417 [==============================] - 601s 1s/step - loss: 0.4186 - accuracy: 0.8576 - val_loss: 1.2696 - val_accuracy: 0.6568\n\nEpoch 38/70\n\n417/417 [==============================] - 620s 1s/step - loss: 0.4157 - accuracy: 0.8574 - val_loss: 1.2298 - val_accuracy: 0.6597\n\nEpoch 39/70\n\n417/417 [==============================] - 593s 1s/step - loss: 0.4215 - accuracy: 0.8562 - val_loss: 0.9973 - val_accuracy: 0.7250\n\nEpoch 40/70\n\n417/417 [==============================] - 592s 1s/step - loss: 0.4041 - accuracy: 0.8612 - val_loss: 1.1854 - val_accuracy: 0.6538\n\nEpoch 41/70\n\n417/417 [==============================] - 605s 1s/step - loss: 0.4087 - accuracy: 0.8581 - val_loss: 1.1174 - val_accuracy: 0.6593\n\nEpoch 42/70\n\n417/417 [==============================] - 617s 1s/step - loss: 0.3874 - accuracy: 0.8660 - val_loss: 1.0474 - val_accuracy: 0.7158\n\nEpoch 43/70\n\n417/417 [==============================] - 622s 1s/step - loss: 0.3882 - accuracy: 0.8667 - val_loss: 0.8879 - val_accuracy: 0.7488\n\nEpoch 44/70\n\n417/417 [==============================] - 606s 1s/step - loss: 0.3822 - accuracy: 0.8696 - val_loss: 0.9843 - val_accuracy: 0.7329\n\nEpoch 45/70\n\n417/417 [==============================] - 622s 1s/step - loss: 0.3696 - accuracy: 0.8740 - val_loss: 1.1331 - val_accuracy: 0.6974\n\nEpoch 46/70\n\n417/417 [==============================] - 608s 1s/step - loss: 0.3675 - accuracy: 0.8726 - val_loss: 0.9981 - val_accuracy: 0.7355\n\nEpoch 47/70\n\n417/417 [==============================] - 615s 1s/step - loss: 0.3552 - accuracy: 0.8798 - val_loss: 1.0515 - val_accuracy: 0.7112\n\nEpoch 48/70\n\n417/417 [==============================] - 621s 1s/step - loss: 0.3781 - accuracy: 0.8719 - val_loss: 0.8512 - val_accuracy: 0.7589\n\nEpoch 49/70\n\n417/417 [==============================] - 610s 1s/step - loss: 0.3550 - accuracy: 0.8782 - val_loss: 1.0610 - val_accuracy: 0.7145\n\nEpoch 50/70\n\n417/417 [==============================] - 631s 2s/step - loss: 0.3558 - accuracy: 0.8793 - val_loss: 1.2056 - val_accuracy: 0.7007\n\nEpoch 51/70\n\n417/417 [==============================] - 605s 1s/step - loss: 0.3547 - accuracy: 0.8795 - val_loss: 0.9709 - val_accuracy: 0.7288\n\nEpoch 52/70\n\n417/417 [==============================] - 614s 1s/step - loss: 0.3412 - accuracy: 0.8820 - val_loss: 0.8435 - val_accuracy: 0.7899\n\nEpoch 53/70\n\n417/417 [==============================] - 630s 2s/step - loss: 0.3416 - accuracy: 0.8827 - val_loss: 0.8985 - val_accuracy: 0.7535\n\nEpoch 54/70\n\n417/417 [==============================] - 602s 1s/step - loss: 0.3305 - accuracy: 0.8889 - val_loss: 1.3090 - val_accuracy: 0.6739\n\nEpoch 55/70\n\n417/417 [==============================] - 631s 2s/step - loss: 0.3229 - accuracy: 0.8902 - val_loss: 0.9061 - val_accuracy: 0.7631\n\nEpoch 56/70\n\n417/417 [==============================] - 600s 1s/step - loss: 0.3373 - accuracy: 0.8827 - val_loss: 1.1578 - val_accuracy: 0.7129\n\nEpoch 57/70\n\n417/417 [==============================] - 596s 1s/step - loss: 0.3321 - accuracy: 0.8854 - val_loss: 1.0337 - val_accuracy: 0.7430\n\nEpoch 58/70\n\n417/417 [==============================] - 589s 1s/step - loss: 0.3112 - accuracy: 0.8946 - val_loss: 1.0961 - val_accuracy: 0.7292\n\nEpoch 59/70\n\n417/417 [==============================] - 588s 1s/step - loss: 0.3092 - accuracy: 0.8952 - val_loss: 0.9165 - val_accuracy: 0.7509\n\nEpoch 60/70\n\n417/417 [==============================] - 587s 1s/step - loss: 0.3082 - accuracy: 0.8939 - val_loss: 1.0162 - val_accuracy: 0.7455\n\nEpoch 61/70\n\n417/417 [==============================] - 601s 1s/step - loss: 0.3063 - accuracy: 0.8943 - val_loss: 1.1379 - val_accuracy: 0.7028\n\nEpoch 62/70\n\n417/417 [==============================] - 613s 1s/step - loss: 0.2973 - accuracy: 0.8972 - val_loss: 1.0810 - val_accuracy: 0.7392\n\nEpoch 63/70\n\n417/417 [==============================] - 630s 2s/step - loss: 0.3030 - accuracy: 0.8954 - val_loss: 1.1623 - val_accuracy: 0.6969\n\nEpoch 64/70\n\n417/417 [==============================] - 599s 1s/step - loss: 0.3010 - accuracy: 0.8979 - val_loss: 1.0614 - val_accuracy: 0.7501\n\nEpoch 65/70\n\n417/417 [==============================] - 605s 1s/step - loss: 0.2990 - accuracy: 0.8970 - val_loss: 0.9049 - val_accuracy: 0.7631\n\nEpoch 66/70\n\n417/417 [==============================] - 621s 1s/step - loss: 0.2978 - accuracy: 0.8967 - val_loss: 1.0967 - val_accuracy: 0.6986\n\nEpoch 67/70\n\n417/417 [==============================] - 605s 1s/step - loss: 0.2982 - accuracy: 0.8979 - val_loss: 0.8418 - val_accuracy: 0.7836\n\nEpoch 68/70\n\n417/417 [==============================] - 610s 1s/step - loss: 0.2900 - accuracy: 0.9005 - val_loss: 0.9980 - val_accuracy: 0.7501\n\nEpoch 69/70\n\n417/417 [==============================] - 630s 2s/step - loss: 0.2802 - accuracy: 0.9039 - val_loss: 0.9892 - val_accuracy: 0.7681\n\nEpoch 70/70\n\n417/417 [==============================] - 601s 1s/step - loss: 0.2785 - accuracy: 0.9049 - val_loss: 0.9119 - val_accuracy: 0.7761\n"}]},{"cell_type":"code","source":"model.save('CNN_model.h5')","metadata":{"id":"T1ZQ5_HzFxnK"},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"img='C:\\\\Users\\\\rubin\\\\Videos\\\\FINAL REVIEW\\\\9-Skin-Cancer\\\\Merged Dataset\\\\Train\\\\Psoriasis pictures Lichen Planus and related diseases\\\\0_36.jpg'","metadata":{"id":"QjQwfD1zUTOs"},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def predict_disease(test_image):\n  img = cv2.imread(test_image)\n  img = img / 255.0\n  img = cv2.resize(img, (224, 224))\n  img = img.reshape(1,224,224,3)\n  prediction = model.predict(img)\n  pred_class = np.argmax(prediction, axis = -1)\n  return pred_class","metadata":{"id":"defyNLsWR-B4"},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"pred=predict_disease(img)\nd=pred[0]","metadata":{"id":"tleGoO24UWRy"},"execution_count":44,"outputs":[{"name":"stdout","output_type":"stream","text":"1/1 [==============================] - 0s 26ms/step\n"}]},{"cell_type":"code","source":"skin_conditions = [    \"Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\",    \"Atopic Dermatitis Photos\",    \"Eczema Photos\",    \"Melanoma Skin Cancer Nevi and Moles\",    \"Nail Fungus and other Nail Disease\",    \"Psoriasis pictures Lichen Planus and related diseases\",    \"Seborrheic Keratoses and other Benign Tumors\",    \"Tinea Ringworm Candidiasis and other Fungal Infections\",    \"Warts Molluscum and other Viral Infections\"]\n","metadata":{"id":"7RZ91P_9UZs6"},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"skin_conditions[d]","metadata":{"id":"btb4E_syUjO_"},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":["'Psoriasis pictures Lichen Planus and related diseases'"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}